{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing CRSP data for backtesting (daily data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&copy; **Johannes Ruf** (comments welcome under j.ruf@lse.ac.uk, February 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook considers daily data instead of monthly data as the previous notebook did. We again construct a dataframe `df` that can be used to backtest systematic trading strategies. The class of trading strategies to be considered are strategies that are functions of the stock capitalizations only (and don't depend on other characteristics, e.g., industries). \n",
    "\n",
    "The dataframe `df` will have three components: a matrix of returns, a matrix of market capitalizations, and a matrix of flags that tag problematic returns.\n",
    "\n",
    "A flag value of 0 implies no special issues. The remaining flag values are constructed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_PROBLEMATIC_INTERMEDIATE_RETURN = 2\n",
    "\n",
    "FLAG_TEMPORARY_DELISTING = 3\n",
    "\n",
    "FLAG_DELRET_MISSING = 4\n",
    "\n",
    "FLAG_MISSING_RETURN_IMPUTED = 5\n",
    "# If return was missing but the trading days before and after have 'good' returns.\n",
    "# The missing returns are replaced by 0.0 on those days.\n",
    "\n",
    "FLAG_RETURN_BASED_ON_BA = 1    \n",
    "# if return is based on a bid-ask average and not corresponding to a missing delisting or a problematic intermediate return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we add 10 to the flag value if the corresponding return is larger/smaller than the following cutoff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUTOFF_LARGE_RETURN = 1   # 1 corresponds to doubling over the period, i.e., a period return of 100%.\n",
    "CUTOFF_SMALL_RETURN = -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If securities are 'temporary delisted' (here defined as previous capitalization is available but returns are missing), we replace the first missing return in a consecutive sequence of missing returns by `TEMPORARY_DELISTING_RETURN`.\n",
    "\n",
    "If delisting returns are missing, we set them to `MISSING_DELIST_RETURN`. \n",
    "\n",
    "Of course, other values or methods to handle these returns are possible, too.  When backtesting trading strategies, robustness checks with respect to these assumptions are recommended (easily implemented thanks to the backtesting flags constructed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPORARY_DELISTING_RETURN = -0.1\n",
    "MISSING_DELIST_RETURN = -0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import wrds\n",
    "WRDS_LOGIN = 'xxx'    # update to your login info on CRSP\n",
    "\n",
    "DATAPATH = '~/Desktop/YOUR_FOLDER_NAME/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = wrds.Connection(wrds_username=WRDS_LOGIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trading strategies we will consider may depend on the stocks' capitalizations. To avoid 'anticipatory' strategies, at any month we are only allowed to use the previous months' capitalizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell takes around 50 minutes on my computer, with a standard broadband connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = db.raw_sql(\"\"\"SELECT d.dlycaldt, d.permno, d.dlyprevcap, d.dlyret, d.dlyprcflg \n",
    "                   FROM crsp.StkDlySecurityData AS d\n",
    "                   JOIN crsp.StkSecurityInfoHist AS s\n",
    "                   ON \n",
    "                   d.permno = s.permno AND s.secinfostartdt <= d.dlycaldt \n",
    "                   AND d.dlycaldt <= s.secinfoenddt\n",
    "                   WHERE \n",
    "                   s.sharetype = 'NS' AND s.securitysubtype = 'COM' \n",
    "                   AND s.issuertype IN ('ACOR','CORP') AND s.usincflg = 'Y'\n",
    "                   \"\"\", date_cols='dlycaldt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the above query does not return the delisting returns (see the warning in Notebook 4). Hence we need to add those returns by hand. The next query returns the delisting returns provided the `StkSecurityInfoHdr` states that the last information of the security satisfies the criteria to be a member of the investment universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_delists = db.raw_sql(\"\"\"SELECT d.dlycaldt, d.permno, d.dlyprevcap, d.dlyret, d.dlyprcflg \n",
    "                   FROM crsp.StkDlySecurityData AS d\n",
    "                   JOIN crsp.StkSecurityInfoHdr AS h\n",
    "                   ON d.permno = h.permno \n",
    "                   WHERE \n",
    "                   h.sharetype = 'NS' AND h.securitysubtype = 'COM' \n",
    "                   AND h.issuertype IN ('ACOR','CORP') AND h.usincflg = 'Y'\n",
    "                   AND d.dlydelflg = 'Y'\n",
    "                   \"\"\", date_cols='dlycaldt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.concat([df, df_delists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For temporary backups, we can store and load intermediate results using the next cells."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "with pd.HDFStore(DATAPATH + 'tmp_daily.h5') as store:\n",
    "    store['df'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with pd.HDFStore(DATAPATH + 'tmp_daily.h5') as store:\n",
    "    df = store['df']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of the cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed with the following steps:\n",
    "1) First, we do some preliminary cleaning steps and add a column to flag critical returns.\n",
    "2) We pivot the data so that each row corresponds to one date, and each column to a `permno`.\n",
    "3) We check and clean the beginning and end of each time series.\n",
    "4) We check and clean for 'temporary delistings' and missing intermediate returns.\n",
    "5) We flag very large/small returns.\n",
    "6) We store the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check whether return are based on bid-ask spreads, and whether CRSP tagged returns as problematic (in particular, if intermediate returns are missing).\n",
    "\n",
    "In contrast to the monthly data, we do *not* entries where `dlyprevcap` is missing. The reason is that even large securities often have days with missing data. (See for the example the case study with IBM in Notebook 2.) For such cases it seems to be better not to remove these securities from the investment universe. We handle these cases below when treating missing intermediate returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A new column and prices based on bid-ask-spreads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now add a new column called `bcktstflg` ('backtesting flag') to the dataframe, where we flag all problematic returns. \n",
    "\n",
    "We first flag all returns that are based on a bid-ask-average instead of a trading price. (Those returns might be re-tagged if they correspond to a missing delisting return.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bl = (df['dlyprcflg']=='BA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This step tages {:_} ({:.2f}%) rows with the BA flag.'.format(\n",
    "    bl.sum(), 100 * bl.sum() / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bcktstflg'] = 0\n",
    "df.loc[bl, 'bcktstflg'] = FLAG_RETURN_BASED_ON_BA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermediate missing and problematic returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of price flags are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['dlyprcflg'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of price flags are there when returns are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['dlyret'].isnull(), 'dlyprcflg'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now find all problematic returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bl = df['dlyret'].isnull() | df['dlyprevcap'].isnull() | df['dlyprcflg'].isin(['NT', 'MP', 'HA', 'SU', 'DM'])\n",
    "df = df.drop('dlyprcflg', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code captures all problematic returns. We have included the flag values `HA` and `SU` for which CRSP doesn't provide any explanations [here](https://www.crsp.org/files/appendix/FlagType_PC.html), see also the warning in Notebook 2.\n",
    "Some of the above tagged returns will be removed below, for example, when appearing at the beginning of a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This step tags {:_} ({:.2f}%) rows.'.format(bl.sum(), 100 * bl.sum() / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[bl, 'bcktstflg'] = FLAG_PROBLEMATIC_INTERMEDIATE_RETURN   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = df.pivot(index='dlycaldt', columns='permno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# check that index is sorted\n",
    "assert df['dlyret'].index.is_monotonic_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the beginning and end of each time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Beginning of each time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean a bit the *beginning* of each time series. We remove entries corresponding to returns of assets that have not yet observed a valid return. Note that the following code cells only change the beginning of each time series. The intuition behind this cleaning step is that in real-time we would only start investing in such securities as soon as they are sufficiently well traded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = df['dlyret'].isnull() | df['dlyprevcap'].isnull() | df['bcktstflg'].gt(0)\n",
    "\n",
    "mask = mask.cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for c in df.columns.levels[0]:\n",
    "    df[c] = df[c].mask(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few time series which correspond to assets in which we never would start investing according to this rule above. Many of these price time series have never observed trading prices (i.e. `dlyprcflg` is set to `BA` throughout).\n",
    "\n",
    "We remove them from the dataframe in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = mask.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} ({:.2f}%) time series without a valid return after removing missing data at the beginning.'.format(\n",
    "            bl.sum(), 100 * bl.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = df.loc[:, df.columns.get_level_values('permno').isin(bl.index[~bl])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delisting and cleaning the end of the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove missing returns at the end of each time series and set missing delisting returns to `MISSING_DELIST_RETURN`. Note that a time series need not have a regular or missing delisting return; for example, if the security is still traded or fell out of the investment universe because of a change in status (e.g. change of `usincflg`).\n",
    "\n",
    "To understand the values of the related column `mthdelflg`, see [here](https://www.crsp.org/files/appendix/FlagType_DE.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = df['dlyret'].isnull() | df['dlyprevcap'].isnull() | df['bcktstflg'].gt(0)\n",
    "\n",
    "mask = mask[::-1].cummin()[::-1]\n",
    "\n",
    "mask = mask.mask(df['bcktstflg'].isnull()[::-1].cummin()[::-1], other=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} ({:.2f}%) time series whose return series at the end are being modified.'.format(\n",
    "    mask.any().sum(), 100 * mask.any().mean()))\n",
    "\n",
    "print('There are {} returns being modified.'.format(mask.sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no `dlyprevcap` corresponding to the first of the problematic days then we need to modify the return on the last non-problematic days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = mask | (mask.shift(-1, fill_value=False) & ~mask & df['dlyprevcap'].isnull().shift(-1, fill_value=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_first_return = mask & ~mask.shift(1, fill_value=False)   \n",
    "# the first of the problematic returns at the end of each problematic time series\n",
    "\n",
    "mask_others = mask & ~mask_first_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['dlyret'] = df['dlyret'].mask(mask_first_return, \n",
    "                                 other=df['dlyret'].fillna(0).add(1).multiply(1 + MISSING_DELIST_RETURN).subtract(1))\n",
    "df['bcktstflg'] = df['bcktstflg'].mask(mask_first_return, other=FLAG_DELRET_MISSING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for c in df.columns.levels[0]:\n",
    "    df[c] = df[c].mask(mask_others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Check that each return time series has at least one value\n",
    "assert df['dlyret'].notnull().any().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# check that if a return is provided then also the previous capitalization is provided\n",
    "assert ~(df['dlyret'].notnull() & df['dlyprevcap'].isnull()).any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary delistings and missing returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now take care of missing returns for securities in the investment universe. Note that by the above manipulations, returns on delisting dates always exist.\n",
    "\n",
    "We distinguish three cases: (a) the previous return exists (security was in the investment universe) and is not problematic, and the following return exists; (b) the previous return exists (security was in the investment universe) and is not problematic, but the following return does not exist; (c) the previous return is problematic or the security was not in the investment universe.\n",
    "\n",
    "In case (a), we consider this situation as a non-trade day for the specific security. We populate `dlyprevcap` with the value on the day after and `dlyret` with 0. (For an example of this situation, recakk the missing price observations for IBM in Notebook 2.)  In case (b), we consider this as a temporary delisting.  In case (c), we assume any temporary delisting effects are already taken into account by the previous returns and we remove the security from the investment universe for that month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `mask` captures all missing returns that follow a problematic (or missing) return (case (c)). The corresponding entries will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = df['dlyret'].isnull() & df['bcktstflg'].notnull() & \\\n",
    "      (df['dlyret'].isnull() | df['bcktstflg'].eq(FLAG_PROBLEMATIC_INTERMEDIATE_RETURN)).shift(1, fill_value=False) \n",
    "\n",
    "#Note that the second `df['dlyret'].isnull()` is required to capture the case when the security was not in the \n",
    "#investment universe on the previous day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} ({:.2f}%) time series for which we remove missing returns from investment universe).\".format(\n",
    "      mask.any().sum(), 100 * mask.any().mean()))\n",
    "print(\"In total, we remove {} returns.\".format(mask.sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for c in df.columns.levels[0]:\n",
    "    df[c] = df[c].mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Check that each return time series has at least one value\n",
    "assert df['dlyret'].notnull().any().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know take care of cases (a) and (b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = df['dlyret'].isnull() & df['bcktstflg'].notnull()\n",
    "mask_tmp_delist = mask & df['dlyret'].isnull().shift(-1, fill_value=False)    # case (b)\n",
    "mask_fillna = mask & ~mask_tmp_delist    # case (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} ({:.2f}%) time series that have temporary delistings.\".format(\n",
    "      mask_tmp_delist.any().sum(), 100 * mask_tmp_delist.any().mean()))\n",
    "print(\"In total, we have {} temporary delistings.\".format(mask_tmp_delist.sum().sum()))\n",
    "\n",
    "print(\"There are {} ({:.2f}%) time series that have missing return sequences of exactly length one.\".format(\n",
    "      mask_fillna.any().sum(), 100 * mask_fillna.any().mean()))\n",
    "print(\"In total, we have {} missing return sequences of exactly length one.\".format(mask_fillna.sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['dlyprevcap'] = df['dlyprevcap'].mask(mask, other=df['dlyprevcap'].fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['dlyret'] = df['dlyret'].mask(mask_tmp_delist, other=TEMPORARY_DELISTING_RETURN)\n",
    "df['bcktstflg'] = df['bcktstflg'].mask(mask_tmp_delist, other=FLAG_TEMPORARY_DELISTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['dlyret'] = df['dlyret'].mask(mask_fillna, other=0.)\n",
    "df['bcktstflg'] = df['bcktstflg'].mask(mask_fillna, other=FLAG_MISSING_RETURN_IMPUTED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for a security that has several delistings and missing return imputs, you could inspect the security with `permno` equal to 12204."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging very large/small returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mask = df['dlyret'].gt(CUTOFF_LARGE_RETURN) | df['dlyret'].lt(CUTOFF_SMALL_RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} very large/small returns, which will be flagged.'.format(mask.sum().sum()))\n",
    "\n",
    "print('These very large/small returns appear in {} ({:.2f}%) time series.'.format(\n",
    "            mask.any().sum(), 100 * mask.any().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['bcktstflg'] = df['bcktstflg'].mask(mask, other=df['bcktstflg'].add(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with pd.HDFStore(DATAPATH + 'CRSP_daily.h5') as store:\n",
    "    store['df'] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some quick summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['bcktstflg'].stack().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df['bcktstflg'].stack().value_counts(normalize=True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
